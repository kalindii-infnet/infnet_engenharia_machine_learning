2024-04-18 20:12:31,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-18 20:12:31,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-18 20:12:31,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-18 20:12:31,183:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-18 20:12:44,858:INFO:PyCaret ClassificationExperiment
2024-04-18 20:12:44,858:INFO:Logging name: clf-default-name
2024-04-18 20:12:44,858:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-18 20:12:44,858:INFO:version 3.2.0
2024-04-18 20:12:44,858:INFO:Initializing setup()
2024-04-18 20:12:44,858:INFO:self.USI: 8fdc
2024-04-18 20:12:44,858:INFO:self._variable_keys: {'n_jobs_param', 'log_plots_param', 'USI', 'html_param', 'y_test', 'exp_id', 'target_param', 'fold_shuffle_param', 'X_test', 'data', 'seed', 'fold_groups_param', 'logging_param', 'fix_imbalance', 'is_multiclass', 'exp_name_log', 'idx', 'memory', '_available_plots', 'gpu_n_jobs_param', 'y', 'y_train', 'pipeline', '_ml_usecase', 'X_train', 'X', 'fold_generator', 'gpu_param'}
2024-04-18 20:12:44,858:INFO:Checking environment
2024-04-18 20:12:44,858:INFO:python_version: 3.8.19
2024-04-18 20:12:44,858:INFO:python_build: ('default', 'Mar 20 2024 19:55:45')
2024-04-18 20:12:44,858:INFO:machine: AMD64
2024-04-18 20:12:44,858:INFO:platform: Windows-10-10.0.19041-SP0
2024-04-18 20:12:44,858:INFO:Memory: svmem(total=25623822336, available=10230886400, percent=60.1, used=15392935936, free=10230886400)
2024-04-18 20:12:44,858:INFO:Physical Core: 8
2024-04-18 20:12:44,859:INFO:Logical Core: 16
2024-04-18 20:12:44,859:INFO:Checking libraries
2024-04-18 20:12:44,859:INFO:System:
2024-04-18 20:12:44,859:INFO:    python: 3.8.19 (default, Mar 20 2024, 19:55:45) [MSC v.1916 64 bit (AMD64)]
2024-04-18 20:12:44,859:INFO:executable: c:\Users\patricia\.conda\envs\infnet-nn3\python.exe
2024-04-18 20:12:44,859:INFO:   machine: Windows-10-10.0.19041-SP0
2024-04-18 20:12:44,859:INFO:PyCaret required dependencies:
2024-04-18 20:12:44,876:INFO:                 pip: 23.3.1
2024-04-18 20:12:44,876:INFO:          setuptools: 68.2.2
2024-04-18 20:12:44,876:INFO:             pycaret: 3.2.0
2024-04-18 20:12:44,876:INFO:             IPython: 8.12.3
2024-04-18 20:12:44,876:INFO:          ipywidgets: 8.1.2
2024-04-18 20:12:44,876:INFO:                tqdm: 4.66.2
2024-04-18 20:12:44,876:INFO:               numpy: 1.24.4
2024-04-18 20:12:44,876:INFO:              pandas: 1.5.3
2024-04-18 20:12:44,876:INFO:              jinja2: 3.1.3
2024-04-18 20:12:44,876:INFO:               scipy: 1.10.1
2024-04-18 20:12:44,876:INFO:              joblib: 1.3.2
2024-04-18 20:12:44,877:INFO:             sklearn: 1.2.2
2024-04-18 20:12:44,877:INFO:                pyod: 1.1.3
2024-04-18 20:12:44,877:INFO:            imblearn: 0.12.0
2024-04-18 20:12:44,877:INFO:   category_encoders: 2.6.3
2024-04-18 20:12:44,877:INFO:            lightgbm: 4.3.0
2024-04-18 20:12:44,877:INFO:               numba: 0.58.1
2024-04-18 20:12:44,877:INFO:            requests: 2.31.0
2024-04-18 20:12:44,877:INFO:          matplotlib: 3.6.0
2024-04-18 20:12:44,877:INFO:          scikitplot: 0.3.7
2024-04-18 20:12:44,877:INFO:         yellowbrick: 1.5
2024-04-18 20:12:44,877:INFO:              plotly: 5.20.0
2024-04-18 20:12:44,877:INFO:    plotly-resampler: Not installed
2024-04-18 20:12:44,877:INFO:             kaleido: 0.2.1
2024-04-18 20:12:44,877:INFO:           schemdraw: 0.15
2024-04-18 20:12:44,877:INFO:         statsmodels: 0.14.1
2024-04-18 20:12:44,877:INFO:              sktime: 0.21.1
2024-04-18 20:12:44,877:INFO:               tbats: 1.1.3
2024-04-18 20:12:44,877:INFO:            pmdarima: 2.0.4
2024-04-18 20:12:44,877:INFO:              psutil: 5.9.0
2024-04-18 20:12:44,877:INFO:          markupsafe: 2.1.5
2024-04-18 20:12:44,877:INFO:             pickle5: Not installed
2024-04-18 20:12:44,877:INFO:         cloudpickle: 3.0.0
2024-04-18 20:12:44,877:INFO:         deprecation: 2.1.0
2024-04-18 20:12:44,877:INFO:              xxhash: 3.4.1
2024-04-18 20:12:44,877:INFO:           wurlitzer: Not installed
2024-04-18 20:12:44,877:INFO:PyCaret optional dependencies:
2024-04-18 20:12:44,890:INFO:                shap: Not installed
2024-04-18 20:12:44,890:INFO:           interpret: Not installed
2024-04-18 20:12:44,890:INFO:                umap: Not installed
2024-04-18 20:12:44,890:INFO:     ydata_profiling: Not installed
2024-04-18 20:12:44,890:INFO:  explainerdashboard: Not installed
2024-04-18 20:12:44,890:INFO:             autoviz: Not installed
2024-04-18 20:12:44,890:INFO:           fairlearn: Not installed
2024-04-18 20:12:44,890:INFO:          deepchecks: Not installed
2024-04-18 20:12:44,890:INFO:             xgboost: Not installed
2024-04-18 20:12:44,890:INFO:            catboost: Not installed
2024-04-18 20:12:44,890:INFO:              kmodes: Not installed
2024-04-18 20:12:44,891:INFO:             mlxtend: Not installed
2024-04-18 20:12:44,891:INFO:       statsforecast: Not installed
2024-04-18 20:12:44,891:INFO:        tune_sklearn: Not installed
2024-04-18 20:12:44,891:INFO:                 ray: Not installed
2024-04-18 20:12:44,891:INFO:            hyperopt: Not installed
2024-04-18 20:12:44,891:INFO:              optuna: Not installed
2024-04-18 20:12:44,891:INFO:               skopt: Not installed
2024-04-18 20:12:44,891:INFO:              mlflow: 2.11.3
2024-04-18 20:12:44,891:INFO:              gradio: Not installed
2024-04-18 20:12:44,891:INFO:             fastapi: Not installed
2024-04-18 20:12:44,891:INFO:             uvicorn: Not installed
2024-04-18 20:12:44,891:INFO:              m2cgen: Not installed
2024-04-18 20:12:44,891:INFO:           evidently: Not installed
2024-04-18 20:12:44,891:INFO:               fugue: Not installed
2024-04-18 20:12:44,891:INFO:           streamlit: 1.32.2
2024-04-18 20:12:44,891:INFO:             prophet: Not installed
2024-04-18 20:12:44,891:INFO:None
2024-04-18 20:12:44,891:INFO:Set up data.
2024-04-18 20:12:44,896:INFO:Set up folding strategy.
2024-04-18 20:12:44,897:INFO:Set up train/test split.
2024-04-18 20:12:44,897:INFO:Set up data.
2024-04-18 20:12:44,901:INFO:Set up index.
2024-04-18 20:12:44,901:INFO:Assigning column types.
2024-04-18 20:12:44,905:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-18 20:12:44,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-18 20:12:44,941:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-18 20:12:44,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:44,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:44,999:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-18 20:12:44,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-18 20:12:45,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,020:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-18 20:12:45,054:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-18 20:12:45,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,108:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-18 20:12:45,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,129:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-18 20:12:45,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,240:INFO:Preparing preprocessing pipeline...
2024-04-18 20:12:45,241:INFO:Set up simple imputation.
2024-04-18 20:12:45,241:INFO:Set up feature normalization.
2024-04-18 20:12:45,264:INFO:Finished creating preprocessing pipeline.
2024-04-18 20:12:45,269:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\patricia\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['lat', 'lon', 'minutes_remaining',
                                             'period', 'playoffs',
                                             'shot_distance'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False)
2024-04-18 20:12:45,269:INFO:Creating final display dataframe.
2024-04-18 20:12:45,337:INFO:Setup _display_container:                     Description             Value
0                    Session id              1646
1                        Target    shot_made_flag
2                   Target type            Binary
3           Original data shape        (20285, 7)
4        Transformed data shape        (20285, 7)
5   Transformed train set shape        (16228, 7)
6    Transformed test set shape         (4057, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator   StratifiedKFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  clf-default-name
20                          USI              8fdc
2024-04-18 20:12:45,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-18 20:12:45,455:INFO:setup() successfully completed in 0.6s...............
2024-04-18 20:12:45,455:INFO:Initializing compare_models()
2024-04-18 20:12:45,455:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, include=['lr', 'dt'], fold=None, round=4, cross_validation=True, sort=f1, n_select=2, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, 'include': ['lr', 'dt'], 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'f1', 'n_select': 2, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-18 20:12:45,455:INFO:Checking exceptions
2024-04-18 20:12:45,458:INFO:Preparing display monitor
2024-04-18 20:12:45,476:INFO:Initializing Logistic Regression
2024-04-18 20:12:45,476:INFO:Total runtime is 0.0 minutes
2024-04-18 20:12:45,479:INFO:SubProcess create_model() called ==================================
2024-04-18 20:12:45,479:INFO:Initializing create_model()
2024-04-18 20:12:45,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A1657D430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-18 20:12:45,479:INFO:Checking exceptions
2024-04-18 20:12:45,480:INFO:Importing libraries
2024-04-18 20:12:45,480:INFO:Copying training dataset
2024-04-18 20:12:45,484:INFO:Defining folds
2024-04-18 20:12:45,484:INFO:Declaring metric variables
2024-04-18 20:12:45,486:INFO:Importing untrained model
2024-04-18 20:12:45,489:INFO:Logistic Regression Imported successfully
2024-04-18 20:12:45,494:INFO:Starting cross validation
2024-04-18 20:12:45,495:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-18 20:12:48,176:INFO:Calculating mean and std
2024-04-18 20:12:48,178:INFO:Creating metrics dataframe
2024-04-18 20:12:48,182:INFO:Uploading results into container
2024-04-18 20:12:48,183:INFO:Uploading model into container now
2024-04-18 20:12:48,183:INFO:_master_model_container: 1
2024-04-18 20:12:48,184:INFO:_display_container: 2
2024-04-18 20:12:48,184:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1646, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-18 20:12:48,184:INFO:create_model() successfully completed......................................
2024-04-18 20:12:48,330:INFO:SubProcess create_model() end ==================================
2024-04-18 20:12:48,330:INFO:Creating metrics dataframe
2024-04-18 20:12:48,338:INFO:Initializing Decision Tree Classifier
2024-04-18 20:12:48,338:INFO:Total runtime is 0.04770410855611165 minutes
2024-04-18 20:12:48,341:INFO:SubProcess create_model() called ==================================
2024-04-18 20:12:48,341:INFO:Initializing create_model()
2024-04-18 20:12:48,341:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A1657D430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-18 20:12:48,342:INFO:Checking exceptions
2024-04-18 20:12:48,342:INFO:Importing libraries
2024-04-18 20:12:48,342:INFO:Copying training dataset
2024-04-18 20:12:48,347:INFO:Defining folds
2024-04-18 20:12:48,347:INFO:Declaring metric variables
2024-04-18 20:12:48,350:INFO:Importing untrained model
2024-04-18 20:12:48,354:INFO:Decision Tree Classifier Imported successfully
2024-04-18 20:12:48,360:INFO:Starting cross validation
2024-04-18 20:12:48,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-18 20:12:49,992:INFO:Calculating mean and std
2024-04-18 20:12:49,994:INFO:Creating metrics dataframe
2024-04-18 20:12:49,998:INFO:Uploading results into container
2024-04-18 20:12:49,999:INFO:Uploading model into container now
2024-04-18 20:12:49,999:INFO:_master_model_container: 2
2024-04-18 20:12:49,999:INFO:_display_container: 2
2024-04-18 20:12:50,000:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best')
2024-04-18 20:12:50,000:INFO:create_model() successfully completed......................................
2024-04-18 20:12:50,143:INFO:SubProcess create_model() end ==================================
2024-04-18 20:12:50,143:INFO:Creating metrics dataframe
2024-04-18 20:12:50,165:INFO:Initializing create_model()
2024-04-18 20:12:50,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-18 20:12:50,165:INFO:Checking exceptions
2024-04-18 20:12:50,168:INFO:Importing libraries
2024-04-18 20:12:50,169:INFO:Copying training dataset
2024-04-18 20:12:50,176:INFO:Defining folds
2024-04-18 20:12:50,176:INFO:Declaring metric variables
2024-04-18 20:12:50,176:INFO:Importing untrained model
2024-04-18 20:12:50,176:INFO:Declaring custom model
2024-04-18 20:12:50,176:INFO:Decision Tree Classifier Imported successfully
2024-04-18 20:12:50,177:INFO:Cross validation set to False
2024-04-18 20:12:50,177:INFO:Fitting Model
2024-04-18 20:12:50,230:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best')
2024-04-18 20:12:50,230:INFO:create_model() successfully completed......................................
2024-04-18 20:12:50,334:INFO:Initializing create_model()
2024-04-18 20:12:50,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1646, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-18 20:12:50,334:INFO:Checking exceptions
2024-04-18 20:12:50,335:INFO:Importing libraries
2024-04-18 20:12:50,335:INFO:Copying training dataset
2024-04-18 20:12:50,339:INFO:Defining folds
2024-04-18 20:12:50,339:INFO:Declaring metric variables
2024-04-18 20:12:50,339:INFO:Importing untrained model
2024-04-18 20:12:50,339:INFO:Declaring custom model
2024-04-18 20:12:50,340:INFO:Logistic Regression Imported successfully
2024-04-18 20:12:50,340:INFO:Cross validation set to False
2024-04-18 20:12:50,340:INFO:Fitting Model
2024-04-18 20:12:50,359:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1646, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-18 20:12:50,359:INFO:create_model() successfully completed......................................
2024-04-18 20:12:50,469:INFO:_master_model_container: 2
2024-04-18 20:12:50,469:INFO:_display_container: 2
2024-04-18 20:12:50,470:INFO:[DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1646, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)]
2024-04-18 20:12:50,470:INFO:compare_models() successfully completed......................................
2024-04-18 20:12:52,196:INFO:Initializing predict_model()
2024-04-18 20:12:52,196:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027A21941C10>)
2024-04-18 20:12:52,196:INFO:Checking exceptions
2024-04-18 20:12:52,196:INFO:Preloading libraries
2024-04-18 20:12:52,391:INFO:Initializing predict_model()
2024-04-18 20:12:52,391:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1646, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027A21700550>)
2024-04-18 20:12:52,391:INFO:Checking exceptions
2024-04-18 20:12:52,392:INFO:Preloading libraries
2024-04-18 20:12:52,563:INFO:Initializing tune_model()
2024-04-18 20:12:52,563:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), fold=None, round=4, n_iter=4, custom_grid=None, optimize=f1, custom_scorer=None, search_library=scikit-learn, search_algorithm=random, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>)
2024-04-18 20:12:52,563:INFO:Checking exceptions
2024-04-18 20:12:52,574:INFO:Copying training dataset
2024-04-18 20:12:52,578:INFO:Checking base model
2024-04-18 20:12:52,578:INFO:Base model : Decision Tree Classifier
2024-04-18 20:12:52,581:INFO:Declaring metric variables
2024-04-18 20:12:52,584:INFO:Defining Hyperparameters
2024-04-18 20:12:52,712:INFO:Tuning with n_jobs=-1
2024-04-18 20:12:52,712:INFO:Initializing RandomizedSearchCV
2024-04-18 20:12:52,926:INFO:best_params: {'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 4, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 7, 'actual_estimator__criterion': 'entropy'}
2024-04-18 20:12:52,926:INFO:Hyperparameter search completed
2024-04-18 20:12:52,926:INFO:SubProcess create_model() called ==================================
2024-04-18 20:12:52,927:INFO:Initializing create_model()
2024-04-18 20:12:52,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000027A21742070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'min_samples_split': 9, 'min_samples_leaf': 4, 'min_impurity_decrease': 0.0001, 'max_features': 'log2', 'max_depth': 7, 'criterion': 'entropy'})
2024-04-18 20:12:52,927:INFO:Checking exceptions
2024-04-18 20:12:52,927:INFO:Importing libraries
2024-04-18 20:12:52,927:INFO:Copying training dataset
2024-04-18 20:12:52,931:INFO:Defining folds
2024-04-18 20:12:52,931:INFO:Declaring metric variables
2024-04-18 20:12:52,934:INFO:Importing untrained model
2024-04-18 20:12:52,934:INFO:Declaring custom model
2024-04-18 20:12:52,937:INFO:Decision Tree Classifier Imported successfully
2024-04-18 20:12:52,943:INFO:Starting cross validation
2024-04-18 20:12:52,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-18 20:12:53,036:INFO:Calculating mean and std
2024-04-18 20:12:53,036:INFO:Creating metrics dataframe
2024-04-18 20:12:53,040:INFO:Finalizing model
2024-04-18 20:12:53,058:INFO:Uploading results into container
2024-04-18 20:12:53,059:INFO:Uploading model into container now
2024-04-18 20:12:53,059:INFO:_master_model_container: 3
2024-04-18 20:12:53,059:INFO:_display_container: 5
2024-04-18 20:12:53,059:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best')
2024-04-18 20:12:53,060:INFO:create_model() successfully completed......................................
2024-04-18 20:12:53,166:INFO:SubProcess create_model() end ==================================
2024-04-18 20:12:53,166:INFO:choose_better activated
2024-04-18 20:12:53,169:INFO:SubProcess create_model() called ==================================
2024-04-18 20:12:53,169:INFO:Initializing create_model()
2024-04-18 20:12:53,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-18 20:12:53,170:INFO:Checking exceptions
2024-04-18 20:12:53,171:INFO:Importing libraries
2024-04-18 20:12:53,171:INFO:Copying training dataset
2024-04-18 20:12:53,175:INFO:Defining folds
2024-04-18 20:12:53,175:INFO:Declaring metric variables
2024-04-18 20:12:53,175:INFO:Importing untrained model
2024-04-18 20:12:53,175:INFO:Declaring custom model
2024-04-18 20:12:53,175:INFO:Decision Tree Classifier Imported successfully
2024-04-18 20:12:53,175:INFO:Starting cross validation
2024-04-18 20:12:53,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-18 20:12:53,317:INFO:Calculating mean and std
2024-04-18 20:12:53,317:INFO:Creating metrics dataframe
2024-04-18 20:12:53,319:INFO:Finalizing model
2024-04-18 20:12:53,365:INFO:Uploading results into container
2024-04-18 20:12:53,365:INFO:Uploading model into container now
2024-04-18 20:12:53,366:INFO:_master_model_container: 4
2024-04-18 20:12:53,366:INFO:_display_container: 6
2024-04-18 20:12:53,366:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best')
2024-04-18 20:12:53,366:INFO:create_model() successfully completed......................................
2024-04-18 20:12:53,469:INFO:SubProcess create_model() end ==================================
2024-04-18 20:12:53,469:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best') result for F1 is 0.5451
2024-04-18 20:12:53,469:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',
                       max_depth=7, max_features='log2', max_leaf_nodes=None,
                       min_impurity_decrease=0.0001, min_samples_leaf=4,
                       min_samples_split=9, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best') result for F1 is 0.466
2024-04-18 20:12:53,470:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best') is best model
2024-04-18 20:12:53,470:INFO:choose_better completed
2024-04-18 20:12:53,470:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-04-18 20:12:53,477:INFO:_master_model_container: 4
2024-04-18 20:12:53,477:INFO:_display_container: 5
2024-04-18 20:12:53,478:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best')
2024-04-18 20:12:53,478:INFO:tune_model() successfully completed......................................
2024-04-18 20:12:53,585:INFO:Initializing predict_model()
2024-04-18 20:12:53,585:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027A21650DC0>)
2024-04-18 20:12:53,586:INFO:Checking exceptions
2024-04-18 20:12:53,586:INFO:Preloading libraries
2024-04-18 20:12:53,766:INFO:Initializing finalize_model()
2024-04-18 20:12:53,766:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-04-18 20:12:53,766:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best')
2024-04-18 20:12:53,769:INFO:Initializing create_model()
2024-04-18 20:12:53,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-04-18 20:12:53,769:INFO:Checking exceptions
2024-04-18 20:12:53,770:INFO:Importing libraries
2024-04-18 20:12:53,770:INFO:Copying training dataset
2024-04-18 20:12:53,770:INFO:Defining folds
2024-04-18 20:12:53,770:INFO:Declaring metric variables
2024-04-18 20:12:53,770:INFO:Importing untrained model
2024-04-18 20:12:53,770:INFO:Declaring custom model
2024-04-18 20:12:53,771:INFO:Decision Tree Classifier Imported successfully
2024-04-18 20:12:53,771:INFO:Cross validation set to False
2024-04-18 20:12:53,771:INFO:Fitting Model
2024-04-18 20:12:53,829:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['lat', 'lon', 'minutes_remaining',
                                             'period', 'playoffs',
                                             'shot_distance'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imp...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=1646, splitter='best'))],
         verbose=False)
2024-04-18 20:12:53,830:INFO:create_model() successfully completed......................................
2024-04-18 20:12:53,932:INFO:_master_model_container: 4
2024-04-18 20:12:53,932:INFO:_display_container: 6
2024-04-18 20:12:53,936:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['lat', 'lon', 'minutes_remaining',
                                             'period', 'playoffs',
                                             'shot_distance'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imp...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=1646, splitter='best'))],
         verbose=False)
2024-04-18 20:12:53,937:INFO:finalize_model() successfully completed......................................
2024-04-18 20:12:54,053:INFO:Initializing save_model()
2024-04-18 20:12:54,053:INFO:save_model(model=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['lat', 'lon', 'minutes_remaining',
                                             'period', 'playoffs',
                                             'shot_distance'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imp...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=1646, splitter='best'))],
         verbose=False), model_name=./model_kobe, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\patricia\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['lat', 'lon', 'minutes_remaining',
                                             'period', 'playoffs',
                                             'shot_distance'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('normalize',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-18 20:12:54,053:INFO:Adding model into prep_pipe
2024-04-18 20:12:54,053:WARNING:Only Model saved as it was a pipeline.
2024-04-18 20:12:54,056:INFO:./model_kobe.pkl saved in current working directory
2024-04-18 20:12:54,061:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['lat', 'lon', 'minutes_remaining',
                                             'period', 'playoffs',
                                             'shot_distance'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imp...
                                    transformer=StandardScaler(copy=True,
                                                               with_mean=True,
                                                               with_std=True))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=1646, splitter='best'))],
         verbose=False)
2024-04-18 20:12:54,061:INFO:save_model() successfully completed......................................
2024-04-18 20:12:54,173:INFO:Initializing load_model()
2024-04-18 20:12:54,173:INFO:load_model(model_name=./model_kobe, platform=None, authentication=None, verbose=True)
2024-04-18 20:12:54,232:WARNING:c:\Users\patricia\.conda\envs\infnet-nn3\lib\site-packages\mlflow\types\utils.py:393: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.
  warnings.warn(

2024-04-18 20:12:57,302:WARNING:c:\Users\patricia\.conda\envs\infnet-nn3\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2024-04-18 20:12:57,374:WARNING:C:\Users\patricia\AppData\Local\Temp\ipykernel_13024\965029737.py:73: FutureWarning: ``mlflow.tracking.client.MlflowClient.get_latest_versions`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.11.3/model-registry.html#migrating-from-stages
  model_version = client.get_latest_versions(registered_model_name)[-1].version

2024-04-18 20:12:57,415:INFO:Initializing predict_model()
2024-04-18 20:12:57,415:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027A23DB7F70>)
2024-04-18 20:12:57,416:INFO:Checking exceptions
2024-04-18 20:12:57,416:INFO:Preloading libraries
2024-04-18 20:12:57,724:INFO:Initializing predict_model()
2024-04-18 20:12:57,724:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1646, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027A23A238B0>)
2024-04-18 20:12:57,724:INFO:Checking exceptions
2024-04-18 20:12:57,724:INFO:Preloading libraries
2024-04-18 20:13:02,077:INFO:Initializing predict_model()
2024-04-18 20:13:02,077:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=1646, splitter='best'), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027A27A034C0>)
2024-04-18 20:13:02,078:INFO:Checking exceptions
2024-04-18 20:13:02,078:INFO:Preloading libraries
2024-04-18 20:13:02,288:INFO:Initializing predict_model()
2024-04-18 20:13:02,288:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000027A73A1A5B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1646, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000027A26467B80>)
2024-04-18 20:13:02,288:INFO:Checking exceptions
2024-04-18 20:13:02,288:INFO:Preloading libraries
